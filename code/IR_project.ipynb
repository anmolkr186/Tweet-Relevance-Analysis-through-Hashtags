{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "IR project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FL-PEzKAyd0",
        "outputId": "66a34524-1967-4978-c585-69ba694ce27d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHqZ4BXsDLmJ",
        "outputId": "43fc5565-5aaa-441f-c8cd-867226025f95"
      },
      "source": [
        "#don't run this part\n",
        "%cd gdrive/My\\ Drive/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C56H-HECDOdi"
      },
      "source": [
        "import tweepy\n",
        "import json\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gduv-6VnDbmC",
        "outputId": "28c8ea4f-f14f-41b0-f377-4e774ed99831"
      },
      "source": [
        "# WorldPoetryDay = pd.read_csv('WorldPoetryDay.csv')\n",
        "Dataset = pd.read_csv('FinalDataset.csv')\n",
        "\n",
        "Dataset = Dataset.iloc[:,:]\n",
        "# print(Dataset.info)\n",
        "print(type(Dataset))\n",
        "# print(Dataset.dtypes)\n",
        "# Dataset = pd.DataFrame(Dataset)\n",
        "# Dataset = Dataset.astype({'favorite_count': int})\n",
        "# Dataset['favorite_count'] = Dataset['favorite_count'].apply(pd.to_numeric)\n",
        "# Dataset[:,'favorite_count'] = Dataset[:,'favorite_count'].astype('i')\n",
        "# Dataset['favorite_count'] = Dataset['favorite_count'].astype(int)\n",
        "print(Dataset.dtypes)\n",
        "print(Dataset)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Unnamed: 0          int64\n",
            "created_at         object\n",
            "res                 int64\n",
            "full_text          object\n",
            "screen_name        object\n",
            "followers_count     int64\n",
            "friends_count       int64\n",
            "retweet_count       int64\n",
            "favorite_count      int64\n",
            "Hashtag            object\n",
            "dtype: object\n",
            "      Unnamed: 0  ...            Hashtag\n",
            "0           1488  ...  godzillavskong  .\n",
            "1           1808  ...         MartyrsDay\n",
            "2            733  ...          GNCTDBill\n",
            "3            111  ...        snyderscut.\n",
            "4            873  ...     instagramdown.\n",
            "...          ...  ...                ...\n",
            "9464        2535  ...  godzillavskong  .\n",
            "9465        1975  ...        snyderscut.\n",
            "9466        1540  ...          GNCTDBill\n",
            "9467        1670  ...          GNCTDBill\n",
            "9468        2522  ...   instagramdown  .\n",
            "\n",
            "[9469 rows x 10 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYM5_aSvESYX",
        "outputId": "4a8aae78-4bac-4193-83a2-ae7aea318ead"
      },
      "source": [
        "DatasetNp = Dataset.to_numpy()\n",
        "# print(DatasetNp[0][8])\n",
        "\n",
        "DatasetNp[:,8] = DatasetNp[:,8].astype('i')\n",
        "\n",
        "# print(DatasetNp.shape)\n",
        "# X, y = WorldPoetryDayNp[:,[2,4,15,22,23]],WorldPoetryDayNp[:,0]\n",
        "X, y = DatasetNp[:,3],DatasetNp[:,2]\n",
        "retweetFavCountX = DatasetNp[:,[5,6,7,8]]\n",
        "retweetFavCountX = retweetFavCountX.astype('f') \n",
        "# print(X.shape)\n",
        "# print(y.shape)\n",
        "# print(retweetFavCountX.shape)\n",
        "# print(X[:5])\n",
        "# print(y[:5])\n",
        "Xn = []\n",
        "yn = []\n",
        "rtn = []\n",
        "for i in range(len(X)):\n",
        "  # print(y[i])\n",
        "  # print(int(y[i]))\n",
        "  if((y[i] == 0 or y[i] == 1) and int(y[i]) >= 2):\n",
        "    continue\n",
        "  else:\n",
        "    Xn.append(X[i])\n",
        "    yn.append(y[i])\n",
        "    rtn.append(retweetFavCountX[i])\n",
        "  # break\n",
        "X = np.array(Xn); y = np.array(yn); retweetFavCountX = np.array(rtn)\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "print(retweetFavCountX.shape)\n",
        "print(X[:5])\n",
        "print(y[:5])\n",
        "print(retweetFavCountX[:5])\n",
        "# print(y.unique())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9469,)\n",
            "(9469,)\n",
            "(9469, 4)\n",
            "['RT @IgnacioDiMeglio: THE REAL SHOWDOWN IS HERE! #GodzillaVsKong is a thing of the past. It´s time for #Killeroo Vs #GorillaMyDreams. Killer…'\n",
            " 'RT @ankush_prashar: On #ShaheedDiwas, great salute to our martyrs #BhagatSingh #Sukhdev &amp; #Rajguru who laid down their lives for the freedo…'\n",
            " 'RT @MANJULtoons: #GNCTDBill\\nMy #cartoon for @firstpost\\nTelegram: https://t.co/0zuidcPdqY https://t.co/AAD6fyoaaR'\n",
            " 'RT @Nadeshot: Wow, #SnydersCut Justice League was absolutely phenomenal. Well worth the wait, all my expectations for the film were blown a…'\n",
            " 'RT @rishabh_memes: #instagramdown \\nAfter going down Instagram coming back online be like : https://t.co/jqrPyNmtHe']\n",
            "[1 1 0 1 1]\n",
            "[[ 397.  804.    5.    0.]\n",
            " [  89.   28.    3.    0.]\n",
            " [ 252.  466.  170.    0.]\n",
            " [  71.  674.  392.    0.]\n",
            " [2484. 1335.   69.   69.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "9AnnovZpAZTm",
        "outputId": "5d1fc11d-65b8-4e57-abcb-e81549839660"
      },
      "source": [
        "#plotting class frequency\n",
        "label = pd.DataFrame(y)\n",
        "classFreq = label[0].value_counts()\n",
        "print(classFreq)\n",
        "classFreq.plot.barh()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    8653\n",
            "0     816\n",
            "Name: 0, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D20ZMCW-A3_o"
      },
      "source": [
        "#run down sampling or up sampling code\n",
        "#for down samplling uncomment below code\n",
        "\n",
        "# length = len(X)\n",
        "# Xn = []; yn = []\n",
        "# for i in range(length):\n",
        "#   if(y[i] == 0):\n",
        "#     yn.append(y[i])\n",
        "#     Xn.append(X[i])\n",
        "#     userX.append(retweetFavCountX[i])\n",
        "\n",
        "# for i in range(4*len(Xn)+20):\n",
        "#   if(y[i] == 1):\n",
        "#     yn.append(y[i])\n",
        "#     Xn.append(X[i])\n",
        "#     userX.append(retweetFavCountX[i])\n",
        "\n",
        "# X = np.array(Xn); y = np.array(yn); retweetFavCountX = np.array(userX)\n",
        "# print(y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dl5is8HGropm",
        "outputId": "6c44ed5f-80d6-4017-a1df-9aacdfacc44b"
      },
      "source": [
        "# up sampling \n",
        "length = len(X)\n",
        "Xn = []; yn = []; userX = []\n",
        "for i in range(6):\n",
        "  for i in range(length):\n",
        "    if(y[i] == 0):\n",
        "      yn.append(y[i])\n",
        "      Xn.append(X[i])\n",
        "      userX.append(retweetFavCountX[i])\n",
        "for i in range(length):\n",
        "  if(y[i] == 1):\n",
        "    yn.append(y[i])\n",
        "    Xn.append(X[i])\n",
        "    userX.append(retweetFavCountX[i])\n",
        "\n",
        "X = np.array(Xn); y = np.array(yn); retweetFavCountX = np.array(userX)\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 1 1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 315
        },
        "id": "oefKEOQ_GzJQ",
        "outputId": "91f4a69e-1ce8-4bba-c80e-9b05c3ed3cbd"
      },
      "source": [
        "#plotting class frequency after up/down samplling\n",
        "label = pd.DataFrame(y)\n",
        "classFreq = label[0].value_counts()\n",
        "print(classFreq)\n",
        "classFreq.plot.barh()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1    8653\n",
            "0    4896\n",
            "Name: 0, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFZFtPPk23xl"
      },
      "source": [
        "# Other Feature Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIKjZQ_IrQs7",
        "outputId": "f4eeb7a1-63d3-45c1-a247-7f22c02b79fe"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(retweetFavCountX, y, test_size=0.33, stratify = y, random_state=37)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9077, 4)\n",
            "(4472, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hDG5gRBfyZ66",
        "outputId": "4a3236e0-8f81-4554-b110-8c69b1dba084"
      },
      "source": [
        "#applying different models\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "MNBclf = MultinomialNB(class_prior = [0.5, 0.5])\n",
        "y_train = y_train.astype('i')\n",
        "print(y_train.dtype)\n",
        "MNBclf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = MNBclf.predict(X_test)\n",
        "print(\"shape of y pred\",y_pred.shape)\n",
        "print(\"shape of y test\",y_test.shape)\n",
        "print(y_pred[:100])\n",
        "print(y_test[:100])\n",
        "y_test = y_test.astype('i')\n",
        "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "# X_trainT\n",
        "#saving model then reading it again\n",
        "pickle.dump(MNBclf, open('otherFeatureMNBclfModel.sav', 'wb'))\n",
        "MNBclf = pickle.load(open('otherFeatureMNBclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "int32\n",
            "shape of y pred (4472,)\n",
            "shape of y test (4472,)\n",
            "[0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
            "[1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0\n",
            " 1 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0\n",
            " 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1]\n",
            "Accuracy:  0.4349284436493739\n",
            "[[1542   74]\n",
            " [2453  403]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.39      0.95      0.55      1616\n",
            "           1       0.84      0.14      0.24      2856\n",
            "\n",
            "    accuracy                           0.43      4472\n",
            "   macro avg       0.62      0.55      0.40      4472\n",
            "weighted avg       0.68      0.43      0.35      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8v440AS5yZ66",
        "outputId": "c8f3b356-c209-4c84-f9be-05b12fd1e5a6"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "LOGclf = LogisticRegression(random_state=0, n_jobs = -1, max_iter = 1000, verbose= 2)\n",
        "LOGclf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = LOGclf.predict(X_test)\n",
        "\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#saving model then reading it again\n",
        "pickle.dump(LOGclf, open('otherFeatureLOGclfModel.sav', 'wb'))\n",
        "LOGclf = pickle.load(open('otherFeatureLOGclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.7s finished\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.3613595706618962\n",
            "[[1616    0]\n",
            " [2856    0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      1.00      0.53      1616\n",
            "           1       0.00      0.00      0.00      2856\n",
            "\n",
            "    accuracy                           0.36      4472\n",
            "   macro avg       0.18      0.50      0.27      4472\n",
            "weighted avg       0.13      0.36      0.19      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SA48LFYKyZ67",
        "outputId": "8abc4eb1-673e-4cfe-f176-9ddf5b235dc5"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier #take more than 3 min (1m2s 75), (27m, 90.8%)\n",
        "KNNclf = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski',n_jobs = -1)\n",
        "KNNclf.fit(X_train, y_train)\n",
        "# Predicting the Test set results\n",
        "y_pred = KNNclf.predict(X_test)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#saving model then reading it again\n",
        "pickle.dump(KNNclf, open('otherFeatureKNNclfModel.sav', 'wb'))\n",
        "KNNclf = pickle.load(open('otherFeatureKNNclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.8866279069767442\n",
            "[[1522   94]\n",
            " [ 413 2443]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.94      0.86      1616\n",
            "           1       0.96      0.86      0.91      2856\n",
            "\n",
            "    accuracy                           0.89      4472\n",
            "   macro avg       0.87      0.90      0.88      4472\n",
            "weighted avg       0.90      0.89      0.89      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyB4DGqUyZ67",
        "outputId": "e29fb43d-466c-4750-febc-99bbcf4b2edb"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "GNBclf = GaussianNB()\n",
        "GNBclf.fit(X_train, y_train)\n",
        "y_pred = GNBclf.predict(X_test)\n",
        "\n",
        "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#saving model then reading it again\n",
        "pickle.dump(GNBclf, open('otherFeatureGNBclfModel.sav', 'wb'))\n",
        "GNBclf = pickle.load(open('otherFeatureGNBclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.3620304114490161\n",
            "[[1616    0]\n",
            " [2853    3]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.36      1.00      0.53      1616\n",
            "           1       1.00      0.00      0.00      2856\n",
            "\n",
            "    accuracy                           0.36      4472\n",
            "   macro avg       0.68      0.50      0.27      4472\n",
            "weighted avg       0.77      0.36      0.19      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0aHmK_T1yZ68",
        "outputId": "c7bf200d-aec9-4500-efa8-24febb020860"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "SVMclf = SVC(probability=False,random_state=1, kernel='rbf')\n",
        "SVMclf.fit(X_train, y_train)\n",
        "# Predicting the Test set results\n",
        "y_pred = SVMclf.predict(X_test)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#saving model then reading it again\n",
        "pickle.dump(SVMclf, open('otherFeatureSVMclfModel.sav', 'wb'))\n",
        "SVMclf = pickle.load(open('otherFeatureSVMclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.6386404293381037\n",
            "[[   0 1616]\n",
            " [   0 2856]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00      1616\n",
            "           1       0.64      1.00      0.78      2856\n",
            "\n",
            "    accuracy                           0.64      4472\n",
            "   macro avg       0.32      0.50      0.39      4472\n",
            "weighted avg       0.41      0.64      0.50      4472\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-DknEqQyZ68",
        "outputId": "0bb58edc-399c-48af-9df2-5e395a92188f"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier  #5s 78%\n",
        "RFclf = RandomForestClassifier(max_depth = 39, bootstrap = True, n_estimators = 1000, criterion = 'gini', random_state = 1,n_jobs = -1, verbose = 1)\n",
        "RFclf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = RFclf.predict(X_test)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "#12>89.44\n",
        "#20>95.7\n",
        "#100, 40, 95.8\n",
        "#100, 35, 95.88\n",
        "#100, pca30, 92\n",
        "#100, w/oPcA 400, 96.03\n",
        "#saving model then reading it again\n",
        "pickle.dump(RFclf, open('otherFeatureRFclfModel.sav', 'wb'))\n",
        "RFclf = pickle.load(open('otherFeatureRFclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:    1.4s\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:    3.3s\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:    5.8s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    7.2s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=2)]: Done 1000 out of 1000 | elapsed:    0.5s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9798747763864043\n",
            "[[1602   14]\n",
            " [  76 2780]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97      1616\n",
            "           1       0.99      0.97      0.98      2856\n",
            "\n",
            "    accuracy                           0.98      4472\n",
            "   macro avg       0.97      0.98      0.98      4472\n",
            "weighted avg       0.98      0.98      0.98      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUt8Y_6tyZ68",
        "outputId": "87f0f8de-46c7-49f6-9d1d-b6092110c505"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier  #5s 78%\n",
        "ETclf = ExtraTreesClassifier(max_depth = 39, bootstrap = True, n_estimators = 1000, criterion = 'gini', random_state = 1,n_jobs = -1, verbose = 1)\n",
        "ETclf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = ETclf.predict(X_test)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "#12>89.44\n",
        "#20>95.7\n",
        "#100, 40, 95.8\n",
        "#100, 35, 95.88\n",
        "#100, pca30, 92\n",
        "#100, w/oPcA 400, 96.03\n",
        "#saving model then reading it again\n",
        "pickle.dump(ETclf, open('otherFeatureETclfModel.sav', 'wb'))\n",
        "ETclf = pickle.load(open('otherFeatureETclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:    1.7s\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:    3.0s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    3.8s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=2)]: Done 1000 out of 1000 | elapsed:    0.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9814400715563506\n",
            "[[1602   14]\n",
            " [  69 2787]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      1616\n",
            "           1       1.00      0.98      0.99      2856\n",
            "\n",
            "    accuracy                           0.98      4472\n",
            "   macro avg       0.98      0.98      0.98      4472\n",
            "weighted avg       0.98      0.98      0.98      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LiLTj1REyZ69",
        "outputId": "9cc67cd9-91a6-4061-fa09-fb1b32d5f54c"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier #(1m 48s 70)\n",
        "MLPclf = MLPClassifier(batch_size = 512, early_stopping=True, hidden_layer_sizes=(256,128,64,32,16), random_state=37 ,max_iter=450, learning_rate_init=0.01, tol=0.0000001,n_iter_no_change = 20) #verbose = True\n",
        "MLPclf.fit(X_train, y_train)\n",
        "# Predicting the Test set results\n",
        "# print(X_train.shape)\n",
        "y_pred = MLPclf.predict(X_test)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "pickle.dump(MLPclf, open('otherFeaturebestMLPModel.sav', 'wb'))\n",
        "MLPclf = pickle.load(open('otherFeaturebestMLPModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.667262969588551\n",
            "[[ 186 1430]\n",
            " [  58 2798]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.12      0.20      1616\n",
            "           1       0.66      0.98      0.79      2856\n",
            "\n",
            "    accuracy                           0.67      4472\n",
            "   macro avg       0.71      0.55      0.49      4472\n",
            "weighted avg       0.70      0.67      0.58      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hiSgNdnIyZ69",
        "outputId": "330df8e8-580b-4dca-c29f-5b8cbb62936f"
      },
      "source": [
        "from xgboost import XGBClassifier #(1m 14s 78)\n",
        "XGBclf = XGBClassifier(max_depth = 15, n_estimators = 2000, n_jobs = -1,random_state=37, verbosity=1)\n",
        "XGBclf.fit(X_train, y_train)\n",
        "y_pred = XGBclf.predict(X_test)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#saving model then reading it again\n",
        "pickle.dump(XGBclf, open('otherFeatureXGBclfModel.sav', 'wb'))\n",
        "XGBclf = pickle.load(open('otherFeatureXGBclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.976520572450805\n",
            "[[1602   14]\n",
            " [  91 2765]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97      1616\n",
            "           1       0.99      0.97      0.98      2856\n",
            "\n",
            "    accuracy                           0.98      4472\n",
            "   macro avg       0.97      0.98      0.97      4472\n",
            "weighted avg       0.98      0.98      0.98      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94FMXOFcyZ69",
        "outputId": "98545cfd-61aa-4e06-8e5c-0ab9b883ec51"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier  #1m 54s 67\n",
        "ADBclf = AdaBoostClassifier(n_estimators=10000, random_state=37, learning_rate = 0.1, algorithm='SAMME')\n",
        "ADBclf.fit(X_train, y_train)\n",
        "y_pred = ADBclf.predict(X_test)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))  \n",
        "print(classification_report(y_test,y_pred))\n",
        "#0.8,1000 > 88.95\n",
        "#0.8, 100 > 82\n",
        "#1, 100 > 84.3\n",
        "#saving model then reading it again\n",
        "pickle.dump(ADBclf, open('otherFeatureADBclfModel.sav', 'wb'))\n",
        "ADBclf = pickle.load(open('otherFeatureADBclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.787567084078712\n",
            "[[ 738  878]\n",
            " [  72 2784]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.46      0.61      1616\n",
            "           1       0.76      0.97      0.85      2856\n",
            "\n",
            "    accuracy                           0.79      4472\n",
            "   macro avg       0.84      0.72      0.73      4472\n",
            "weighted avg       0.81      0.79      0.77      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0dxjgX_yZ6-",
        "outputId": "bf29ade6-790f-48c0-af08-1441ec05acca"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier #6 min #13s 69 #2m6s 73\n",
        "GBclf = GradientBoostingClassifier(n_estimators=5000, learning_rate=0.2,max_depth=5, random_state=37, verbose = 1)\n",
        "GBclf.fit(X_train, y_train)\n",
        "y_pred = GBclf.predict(X_test)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))  \n",
        "print(classification_report(y_test,y_pred))\n",
        "#saving model then reading it again\n",
        "pickle.dump(GBclf, open('otherFeatureGBclfModel.sav', 'wb'))\n",
        "GBclf = pickle.load(open('otherFeatureGBclfModel.sav', 'rb'))\n",
        "#89"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.1671            1.04m\n",
            "         2           1.0744           58.75s\n",
            "         3           1.0069           57.81s\n",
            "         4           0.9581           57.30s\n",
            "         5           0.9219           57.08s\n",
            "         6           0.8912           58.53s\n",
            "         7           0.8662           59.83s\n",
            "         8           0.8453           59.74s\n",
            "         9           0.8300           59.43s\n",
            "        10           0.8136           59.19s\n",
            "        20           0.7163           57.17s\n",
            "        30           0.6330           56.63s\n",
            "        40           0.5755           56.42s\n",
            "        50           0.5218           55.89s\n",
            "        60           0.4787           55.49s\n",
            "        70           0.4354           55.47s\n",
            "        80           0.4097           55.43s\n",
            "        90           0.3830           55.22s\n",
            "       100           0.3561           55.37s\n",
            "       200           0.1906           53.77s\n",
            "       300           0.1187           52.28s\n",
            "       400           0.0801           50.95s\n",
            "       500           0.0597           49.72s\n",
            "       600           0.0453           48.53s\n",
            "       700           0.0368           47.38s\n",
            "       800           0.0318           46.22s\n",
            "       900           0.0289           45.25s\n",
            "      1000           0.0270           44.10s\n",
            "      2000           0.0237           32.56s\n",
            "      3000           0.0236           21.21s\n",
            "      4000           0.0236           10.49s\n",
            "      5000           0.0236            0.00s\n",
            "Testing accuracy: 0.9785330948121646\n",
            "[[1602   14]\n",
            " [  82 2774]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97      1616\n",
            "           1       0.99      0.97      0.98      2856\n",
            "\n",
            "    accuracy                           0.98      4472\n",
            "   macro avg       0.97      0.98      0.98      4472\n",
            "weighted avg       0.98      0.98      0.98      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BVQHkXnyZ6-",
        "outputId": "97224c75-648a-4527-c865-827579eedcbf"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "RFclf = RandomForestClassifier(max_depth = 39, bootstrap = True, n_estimators = 1000, criterion = 'gini', random_state = 1,n_jobs = -1, verbose = 1)\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "# ETclf = ExtraTreesClassifier(max_depth = 39, bootstrap = True, n_estimators = 500, criterion = 'gini', n_jobs = -1,max_samples=0.8,max_features=6,random_state=37)\n",
        "ETclf = ExtraTreesClassifier(max_depth = 39, bootstrap = True, n_estimators = 1000, criterion = 'gini', random_state = 1,n_jobs = -1, verbose = 1)\n",
        "\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "MNBclf = MultinomialNB()\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier #take more than 3 min\n",
        "KNNclf = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski',n_jobs = -1)\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier #\n",
        "MLPclf = MLPClassifier(batch_size = 512, early_stopping=True, hidden_layer_sizes=(256,128,64,32,16), random_state=37 ,max_iter=450, learning_rate_init=0.01, tol=0.0000001,n_iter_no_change = 20) #, verbose = True\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression #\n",
        "LOGclf = LogisticRegression(random_state=0, n_jobs = -1, max_iter = 200, verbose= 1)\n",
        "\n",
        "from sklearn.svm import SVC #\n",
        "SVMclf = SVC(probability=False,random_state=1, kernel='rbf')\n",
        "\n",
        "from xgboost import XGBClassifier #\n",
        "XGBclf = XGBClassifier(max_depth = 15, n_estimators = 10000, n_jobs = -1,random_state=37, verbosity=1)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ADBclf = AdaBoostClassifier(n_estimators=30000, random_state=37, learning_rate = 0.1, algorithm='SAMME')\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier #6 min\n",
        "GBclf = GradientBoostingClassifier(n_estimators=5000, learning_rate=0.2,max_depth=5, random_state=37, verbose = 1)\n",
        "\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "otherFeatureclf = VotingClassifier(estimators=[('RFclf', RFclf),('ETclf', ETclf),('KNNclf', KNNclf),('XGBclf', XGBclf),  ('GBclf', GBclf),  ('ADBclf', ADBclf)], voting='hard', weights=[2,2,2,2,2,1], flatten_transform=True)\n",
        "otherFeatureclf.fit(X_train, y_train)\n",
        "y_pred_otherFeature = otherFeatureclf.predict(X_test)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred_otherFeature)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred_otherFeature))  \n",
        "print(classification_report(y_test,y_pred_otherFeature))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 390 tasks      | elapsed:    3.7s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    8.3s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 540 tasks      | elapsed:    2.3s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    4.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.1671            1.06m\n",
            "         2           1.0744            1.00m\n",
            "         3           1.0069           58.69s\n",
            "         4           0.9581           57.97s\n",
            "         5           0.9219           57.82s\n",
            "         6           0.8912           57.61s\n",
            "         7           0.8662           57.39s\n",
            "         8           0.8453           57.26s\n",
            "         9           0.8300           57.32s\n",
            "        10           0.8136           57.27s\n",
            "        20           0.7163           56.81s\n",
            "        30           0.6330           56.04s\n",
            "        40           0.5755           56.50s\n",
            "        50           0.5218           55.98s\n",
            "        60           0.4787           56.19s\n",
            "        70           0.4354           56.15s\n",
            "        80           0.4097           56.30s\n",
            "        90           0.3830           56.15s\n",
            "       100           0.3561           56.08s\n",
            "       200           0.1906           53.80s\n",
            "       300           0.1187           52.55s\n",
            "       400           0.0801           51.47s\n",
            "       500           0.0597           50.28s\n",
            "       600           0.0453           49.17s\n",
            "       700           0.0368           48.13s\n",
            "       800           0.0318           46.99s\n",
            "       900           0.0289           45.90s\n",
            "      1000           0.0270           44.65s\n",
            "      2000           0.0237           32.62s\n",
            "      3000           0.0236           21.30s\n",
            "      4000           0.0236           10.56s\n",
            "      5000           0.0236            0.00s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    0.2s\n",
            "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:    0.4s\n",
            "[Parallel(n_jobs=2)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 1000 out of 1000 | elapsed:    0.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9805456171735242\n",
            "[[1602   14]\n",
            " [  73 2783]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97      1616\n",
            "           1       0.99      0.97      0.98      2856\n",
            "\n",
            "    accuracy                           0.98      4472\n",
            "   macro avg       0.98      0.98      0.98      4472\n",
            "weighted avg       0.98      0.98      0.98      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8CuOa8OwEUP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af3df4ef-297a-4f04-dc36-6c219c62dc9c"
      },
      "source": [
        "otherFeatureclf.fit(retweetFavCountX, y)\n",
        "\n",
        "#saving model then reading it again\n",
        "pickle.dump(otherFeatureclf, open('otherFeaturefinalBestModel.sav', 'wb'))\n",
        "otherFeatureclf = pickle.load(open('otherFeaturefinalBestModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 230 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   11.2s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 540 tasks      | elapsed:    2.8s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:    5.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.1724            1.39m\n",
            "         2           1.0779            1.35m\n",
            "         3           1.0127            1.34m\n",
            "         4           0.9630            1.33m\n",
            "         5           0.9262            1.33m\n",
            "         6           0.8958            1.33m\n",
            "         7           0.8724            1.32m\n",
            "         8           0.8526            1.32m\n",
            "         9           0.8395            1.32m\n",
            "        10           0.8231            1.32m\n",
            "        20           0.7250            1.32m\n",
            "        30           0.6351            1.31m\n",
            "        40           0.5865            1.31m\n",
            "        50           0.5401            1.30m\n",
            "        60           0.4958            1.31m\n",
            "        70           0.4624            1.31m\n",
            "        80           0.4257            1.30m\n",
            "        90           0.3972            1.30m\n",
            "       100           0.3713            1.29m\n",
            "       200           0.2025            1.27m\n",
            "       300           0.1306            1.24m\n",
            "       400           0.0883            1.21m\n",
            "       500           0.0645            1.19m\n",
            "       600           0.0500            1.16m\n",
            "       700           0.0412            1.13m\n",
            "       800           0.0357            1.10m\n",
            "       900           0.0319            1.08m\n",
            "      1000           0.0295            1.05m\n",
            "      2000           0.0251           46.32s\n",
            "      3000           0.0250           30.26s\n",
            "      4000           0.0250           14.98s\n",
            "      5000           0.0249            0.00s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MORh4ue8Bbs"
      },
      "source": [
        "# With count vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTOdsFAb2v1h",
        "outputId": "082920b6-fae0-4137-b383-8df85bdc3dfe"
      },
      "source": [
        "import glob\n",
        "import nltk\n",
        "import string\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def preprocessing(doc):\n",
        "  puncd = {  }\n",
        "  for i in string.punctuation:\n",
        "    puncd[i] = ' '\n",
        "  doc = doc.translate(str.maketrans(puncd))                     #replacing the punctuation marks with white spaces. \n",
        "  doc = doc.strip()                                             #removing the extra white space characters. \n",
        "  doc = doc.lower()                                             #making the string to lower case letters. \n",
        "\n",
        "  tokens = word_tokenize(doc)                                         #tokenise the words to a list. \n",
        "  tokens_NoStop = [i for i in tokens if i not in stop_words]                #removing the stop words from the tokenised list. \n",
        "  lemmatizer=WordNetLemmatizer()\n",
        "  lemmedWordtext = []\n",
        "  for i in range(len(tokens_NoStop)):\n",
        "    lemmedWordtext.append(lemmatizer.lemmatize(tokens_NoStop[i]))           #appending the lemmatized word in the list\n",
        "  return lemmedWordtext\n",
        "Xnew = []\n",
        "for i in range(len(X)):\n",
        "  preProcessed = preprocessing(X[i])\n",
        "  # print(preProcessed)\n",
        "  # preProcessed.append(X[i][1])\n",
        "  # preProcessed.append(X[i][2])\n",
        "  Xnew.append(preProcessed)\n",
        "\n",
        "print(Xnew[:5])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[['rt', 'manjultoons', 'gnctdbill', 'cartoon', 'firstpost', 'telegram', 'http', 'co', '0zuidcpdqy', 'http', 'co', 'aad6fyoaar'], ['rt', 'saahilmenghani', 'number', 'shoot', 'farmersprotest', 'site', 'young', 'farmer', 'arrive', 'village', 'martyrsday', 'शहीद', 'दिवस', 'singhu…'], ['rt', 'saahilmenghani', 'number', 'shoot', 'farmersprotest', 'site', 'young', 'farmer', 'arrive', 'village', 'martyrsday', 'शहीद', 'दिवस', 'singhu…'], ['started', 'trending', 'pakistan', 'instagramdown', 'ufff', 'happiest', 'great', 'job', 'sheikh', 'nawaz', 'sharif', 'louis', 'tomlinson', 'selena', 'hayeee', 'trump', 'itne', 'china', 'islam', 'south', 'punjab', 'almighty', 'allah', 'dm', 'aray', 'bilkul'], ['create', 'modern', 'flat', 'modern', 'web', 'ui', 'illustration', 'design', 'website', 'mobile', 'app', 'feel', 'free', 'contact', 'http', 'co', 'jhnnf64zz2', 'web', 'illustration', 'flat', 'illustration', 'graphic', 'design', 'saweetie', 'marchmadness', 'instagramdown', 'colgate', 'freecodefridaycontest']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTYRzoZSrnQX",
        "outputId": "b7747b0a-f738-4de5-a5b6-57f33b2189d4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, stratify = y, random_state=37)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(9077,)\n",
            "(4472,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAt4odW16Qzr",
        "outputId": "42d610c1-2eda-4d90-b895-07394f93c1d2"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import CountVectorizer             #vectorizing text data\n",
        "vectorizer = CountVectorizer(tokenizer = preprocessing)#,stop_words=stop_words\n",
        "X_trainT = vectorizer.fit_transform(X_train)\n",
        "features = vectorizer.get_feature_names()\n",
        "print(\"No of features after vectorizing X_train:\", len(features))\n",
        "X_testT  = vectorizer.transform(X_test)\n",
        "print(\"shape of X_trainT:\", X_trainT.shape)\n",
        "X_T = vectorizer.fit_transform(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of features after vectorizing X_train: 10685\n",
            "shape of X_trainT: (9077, 10685)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIDQMAD6NkZe",
        "outputId": "45a7cb88-0fb4-4140-b8f0-0b7a699005f6"
      },
      "source": [
        "#applying different models\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "MNBclf = MultinomialNB(class_prior = [0.5, 0.5])\n",
        "y_train = y_train.astype('i')\n",
        "print(y_train.dtype)\n",
        "MNBclf.fit(X_trainT, y_train)\n",
        "\n",
        "y_pred = MNBclf.predict(X_testT)\n",
        "print(\"shape of y pred\",y_pred.shape)\n",
        "print(\"shape of y test\",y_test.shape)\n",
        "print(y_pred[:100])\n",
        "print(y_test[:100])\n",
        "y_test = y_test.astype('i')\n",
        "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "# X_trainT\n",
        "#saving model then reading it again\n",
        "pickle.dump(MNBclf, open('MNBclfModel.sav', 'wb'))\n",
        "MNBclf = pickle.load(open('MNBclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "int32\n",
            "shape of y pred (4472,)\n",
            "shape of y test (4472,)\n",
            "[1 0 1 1 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0 1 0\n",
            " 1 1 1 1 0 1 0 0 1 1 0 0 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0\n",
            " 0 1 0 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0]\n",
            "[1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0\n",
            " 1 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0\n",
            " 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1]\n",
            "Accuracy:  0.9579606440071556\n",
            "[[1552   64]\n",
            " [ 124 2732]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.94      1616\n",
            "           1       0.98      0.96      0.97      2856\n",
            "\n",
            "    accuracy                           0.96      4472\n",
            "   macro avg       0.95      0.96      0.95      4472\n",
            "weighted avg       0.96      0.96      0.96      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghtVkmwmFBqy",
        "outputId": "d1010558-6148-4627-e928-4bf94f75bbc5"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "LOGclf = LogisticRegression(random_state=0, n_jobs = -1, max_iter = 1000, verbose= 2)\n",
        "LOGclf.fit(X_trainT, y_train)\n",
        "\n",
        "y_pred = LOGclf.predict(X_testT)\n",
        "\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#saving model then reading it again\n",
        "pickle.dump(LOGclf, open('LOGclfModel.sav', 'wb'))\n",
        "LOGclf = pickle.load(open('LOGclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.8s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9780858676207513\n",
            "[[1580   36]\n",
            " [  62 2794]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1616\n",
            "           1       0.99      0.98      0.98      2856\n",
            "\n",
            "    accuracy                           0.98      4472\n",
            "   macro avg       0.97      0.98      0.98      4472\n",
            "weighted avg       0.98      0.98      0.98      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE4b7IFMMQYk",
        "outputId": "206e4d46-7d3f-4ef7-a48d-e588b6e574ef"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier #take more than 3 min (1m2s 75), (27m, 90.8%)\n",
        "KNNclf = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski',n_jobs = -1)\n",
        "KNNclf.fit(X_trainT, y_train)\n",
        "# Predicting the Test set results\n",
        "y_pred = KNNclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#saving model then reading it again\n",
        "pickle.dump(KNNclf, open('KNNclfModel.sav', 'wb'))\n",
        "KNNclf = pickle.load(open('KNNclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9279964221824687\n",
            "[[1556   60]\n",
            " [ 262 2594]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.96      0.91      1616\n",
            "           1       0.98      0.91      0.94      2856\n",
            "\n",
            "    accuracy                           0.93      4472\n",
            "   macro avg       0.92      0.94      0.92      4472\n",
            "weighted avg       0.93      0.93      0.93      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALB-41OIMWyQ",
        "outputId": "c07b3d1a-5430-471e-bf5a-970cf981138c"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "GNBclf = GaussianNB()\n",
        "GNBclf.fit(X_trainT.toarray(), y_train)\n",
        "y_pred = GNBclf.predict(X_testT.toarray())\n",
        "\n",
        "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#saving model then reading it again\n",
        "pickle.dump(GNBclf, open('GNBclfModel.sav', 'wb'))\n",
        "GNBclf = pickle.load(open('GNBclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8678443649373881\n",
            "[[1616    0]\n",
            " [ 591 2265]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      1.00      0.85      1616\n",
            "           1       1.00      0.79      0.88      2856\n",
            "\n",
            "    accuracy                           0.87      4472\n",
            "   macro avg       0.87      0.90      0.87      4472\n",
            "weighted avg       0.90      0.87      0.87      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_zTd1RHMiyF",
        "outputId": "a1b093c1-7043-4b8c-dc81-86d9fefac861"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "SVMclf = SVC(probability=False,random_state=1, kernel='rbf')\n",
        "SVMclf.fit(X_trainT, y_train)\n",
        "# Predicting the Test set results\n",
        "y_pred = SVMclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#saving model then reading it again\n",
        "pickle.dump(SVMclf, open('SVMclfModel.sav', 'wb'))\n",
        "SVMclf = pickle.load(open('SVMclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9787567084078712\n",
            "[[1570   46]\n",
            " [  49 2807]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97      1616\n",
            "           1       0.98      0.98      0.98      2856\n",
            "\n",
            "    accuracy                           0.98      4472\n",
            "   macro avg       0.98      0.98      0.98      4472\n",
            "weighted avg       0.98      0.98      0.98      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R4_R5evOMmcV",
        "outputId": "d0ba2b96-5bcb-4b85-87b4-f7cb4567fab3"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier  #5s 78%\n",
        "RFclf = RandomForestClassifier(max_depth = 39, bootstrap = True, n_estimators = 1000, criterion = 'gini', random_state = 1,n_jobs = -1, verbose = 1)\n",
        "RFclf.fit(X_trainT, y_train)\n",
        "\n",
        "y_pred = RFclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "#12>89.44\n",
        "#20>95.7\n",
        "#100, 40, 95.8\n",
        "#100, 35, 95.88\n",
        "#100, pca30, 92\n",
        "#100, w/oPcA 400, 96.03\n",
        "#saving model then reading it again\n",
        "pickle.dump(RFclf, open('RFclfModel.sav', 'wb'))\n",
        "RFclf = pickle.load(open('RFclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:    7.0s\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:   12.4s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   15.5s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9237477638640429\n",
            "[[1305  311]\n",
            " [  30 2826]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.81      0.88      1616\n",
            "           1       0.90      0.99      0.94      2856\n",
            "\n",
            "    accuracy                           0.92      4472\n",
            "   macro avg       0.94      0.90      0.91      4472\n",
            "weighted avg       0.93      0.92      0.92      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOqtmNx3MyDO",
        "outputId": "54f5e489-f5d5-4d2d-cc62-a82fc945f549"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier  #5s 78%\n",
        "ETclf = ExtraTreesClassifier(max_depth = 39, bootstrap = True, n_estimators = 1000, criterion = 'gini', random_state = 1,n_jobs = -1, verbose = 1)\n",
        "ETclf.fit(X_trainT, y_train)\n",
        "\n",
        "y_pred = ETclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "#12>89.44\n",
        "#20>95.7\n",
        "#100, 40, 95.8\n",
        "#100, 35, 95.88\n",
        "#100, pca30, 92\n",
        "#100, w/oPcA 400, 96.03\n",
        "#saving model then reading it again\n",
        "pickle.dump(ETclf, open('ETclfModel.sav', 'wb'))\n",
        "ETclf = pickle.load(open('ETclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    0.6s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:    2.6s\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:    6.1s\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:   10.9s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   13.7s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9116726296958855\n",
            "[[1249  367]\n",
            " [  28 2828]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.77      0.86      1616\n",
            "           1       0.89      0.99      0.93      2856\n",
            "\n",
            "    accuracy                           0.91      4472\n",
            "   macro avg       0.93      0.88      0.90      4472\n",
            "weighted avg       0.92      0.91      0.91      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slKiM5rZMt2b",
        "outputId": "f5b86fa0-2cbe-4d5e-88b6-25119ee2450c"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier #(1m 48s 70)\n",
        "MLPclf = MLPClassifier(batch_size = 512, early_stopping=True, hidden_layer_sizes=(256,128,64,32,16), random_state=37 ,max_iter=450, learning_rate_init=0.01, tol=0.0000001,n_iter_no_change = 20) #verbose = True\n",
        "MLPclf.fit(X_trainT, y_train)\n",
        "# Predicting the Test set results\n",
        "# print(X_train.shape)\n",
        "y_pred = MLPclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "pickle.dump(MLPclf, open('bestMLPModel.sav', 'wb'))\n",
        "MLPclf = pickle.load(open('bestMLPModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9780858676207513\n",
            "[[1585   31]\n",
            " [  67 2789]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1616\n",
            "           1       0.99      0.98      0.98      2856\n",
            "\n",
            "    accuracy                           0.98      4472\n",
            "   macro avg       0.97      0.98      0.98      4472\n",
            "weighted avg       0.98      0.98      0.98      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LOFMCOCRNDQI",
        "outputId": "0df2dbaf-b12a-4ed3-fcbd-71a7000c6bda"
      },
      "source": [
        "from xgboost import XGBClassifier #(1m 14s 78)\n",
        "XGBclf = XGBClassifier(max_depth = 15, n_estimators = 2000, n_jobs = -1,random_state=37, verbosity=1)\n",
        "XGBclf.fit(X_trainT, y_train)\n",
        "y_pred = XGBclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#saving model then reading it again\n",
        "pickle.dump(XGBclf, open('XGBclfModel.sav', 'wb'))\n",
        "XGBclf = pickle.load(open('XGBclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9762969588550984\n",
            "[[1588   28]\n",
            " [  78 2778]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97      1616\n",
            "           1       0.99      0.97      0.98      2856\n",
            "\n",
            "    accuracy                           0.98      4472\n",
            "   macro avg       0.97      0.98      0.97      4472\n",
            "weighted avg       0.98      0.98      0.98      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHyonEFYNLMH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40772067-f2e7-4c05-e155-bd0f8de39867"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier  #1m 54s 67\n",
        "ADBclf = AdaBoostClassifier(n_estimators=10000, random_state=37, learning_rate = 0.1, algorithm='SAMME')\n",
        "ADBclf.fit(X_trainT, y_train)\n",
        "y_pred = ADBclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))  \n",
        "print(classification_report(y_test,y_pred))\n",
        "#0.8,1000 > 88.95\n",
        "#0.8, 100 > 82\n",
        "#1, 100 > 84.3\n",
        "#saving model then reading it again\n",
        "pickle.dump(ADBclf, open('ADBclfModel.sav', 'wb'))\n",
        "ADBclf = pickle.load(open('ADBclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.8747763864042933\n",
            "[[1132  484]\n",
            " [  76 2780]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.70      0.80      1616\n",
            "           1       0.85      0.97      0.91      2856\n",
            "\n",
            "    accuracy                           0.87      4472\n",
            "   macro avg       0.89      0.84      0.86      4472\n",
            "weighted avg       0.88      0.87      0.87      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7xQ_xQMNP1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45d3d4cf-b788-48c3-911d-70bd385ee4e5"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier #6 min #13s 69 #2m6s 73\n",
        "GBclf = GradientBoostingClassifier(n_estimators=5000, learning_rate=0.2,max_depth=5, random_state=37, verbose = 1)\n",
        "GBclf.fit(X_trainT, y_train)\n",
        "y_pred = GBclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))  \n",
        "print(classification_report(y_test,y_pred))\n",
        "#saving model then reading it again\n",
        "pickle.dump(GBclf, open('GBclfModel.sav', 'wb'))\n",
        "GBclf = pickle.load(open('GBclfModel.sav', 'rb'))\n",
        "#89"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.1470            2.47m\n",
            "         2           1.0427            2.34m\n",
            "         3           0.9663            2.29m\n",
            "         4           0.9151            2.24m\n",
            "         5           0.8701            2.24m\n",
            "         6           0.8359            2.22m\n",
            "         7           0.8004            2.22m\n",
            "         8           0.7780            2.20m\n",
            "         9           0.7477            2.27m\n",
            "        10           0.7252            2.25m\n",
            "        20           0.6153            2.19m\n",
            "        30           0.5479            2.11m\n",
            "        40           0.5001            2.06m\n",
            "        50           0.4566            2.08m\n",
            "        60           0.4238            2.03m\n",
            "        70           0.3959            2.00m\n",
            "        80           0.3772            1.96m\n",
            "        90           0.3583            1.95m\n",
            "       100           0.3398            1.93m\n",
            "       200           0.2394            1.79m\n",
            "       300           0.1906            1.71m\n",
            "       400           0.1606            1.66m\n",
            "       500           0.1406            1.61m\n",
            "       600           0.1282            1.57m\n",
            "       700           0.1191            1.54m\n",
            "       800           0.1128            1.50m\n",
            "       900           0.1083            1.46m\n",
            "      1000           0.1051            1.43m\n",
            "      2000           0.0952            1.08m\n",
            "      3000           0.0936           43.59s\n",
            "      4000           0.0930           21.91s\n",
            "      5000           0.0928            0.00s\n",
            "Testing accuracy: 0.9796511627906976\n",
            "[[1590   26]\n",
            " [  65 2791]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1616\n",
            "           1       0.99      0.98      0.98      2856\n",
            "\n",
            "    accuracy                           0.98      4472\n",
            "   macro avg       0.98      0.98      0.98      4472\n",
            "weighted avg       0.98      0.98      0.98      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmhaBFBVLvDi",
        "outputId": "da319a21-a0ec-4388-e6bd-56c2fa3f0ff7"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "RFclf = RandomForestClassifier(max_depth = 39, bootstrap = True, n_estimators = 1000, criterion = 'gini', random_state = 1,n_jobs = -1, verbose = 1)\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "# ETclf = ExtraTreesClassifier(max_depth = 39, bootstrap = True, n_estimators = 500, criterion = 'gini', n_jobs = -1,max_samples=0.8,max_features=6,random_state=37)\n",
        "ETclf = ExtraTreesClassifier(max_depth = 39, bootstrap = True, n_estimators = 1000, criterion = 'gini', random_state = 1,n_jobs = -1, verbose = 1)\n",
        "\n",
        "\n",
        "# from sklearn.naive_bayes import MultinomialNB\n",
        "# MNBclf = MultinomialNB()\n",
        "\n",
        "# from sklearn.neighbors import KNeighborsClassifier #take more than 3 min\n",
        "# KNNclf = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski',n_jobs = -1)\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier #\n",
        "MLPclf = MLPClassifier(batch_size = 512, early_stopping=True, hidden_layer_sizes=(256,128,64,32,16), random_state=37 ,max_iter=450, learning_rate_init=0.01, tol=0.0000001,n_iter_no_change = 20) #verbose = True\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression #\n",
        "LOGclf = LogisticRegression(random_state=0, n_jobs = -1, max_iter = 200, verbose= 1)\n",
        "\n",
        "from sklearn.svm import SVC #\n",
        "SVMclf = SVC(probability=False,random_state=1, kernel='rbf')\n",
        "\n",
        "from xgboost import XGBClassifier #\n",
        "XGBclf = XGBClassifier(max_depth = 15, n_estimators = 10000, n_jobs = -1,random_state=37, verbosity=1)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ADBclf = AdaBoostClassifier(n_estimators=30000, random_state=37, learning_rate = 0.1, algorithm='SAMME')\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier #6 min\n",
        "GBclf = GradientBoostingClassifier(n_estimators=5000, learning_rate=0.2,max_depth=5, random_state=37, verbose = 1)\n",
        "\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "countVecclf = VotingClassifier(estimators=[('RFclf', RFclf),('ETclf', ETclf),('MLPclf', MLPclf),('LOGclf', LOGclf),('SVMclf', SVMclf), ('XGBclf', XGBclf),  ('ADBclf', ADBclf),('GBclf', GBclf)], voting='hard', weights=[1,1,2,2,2,2,1,2], flatten_transform=True)\n",
        "countVecclf.fit(X_trainT, y_train)\n",
        "y_pred_countVec = countVecclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred_countVec)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred_countVec))  \n",
        "print(classification_report(y_test,y_pred_countVec))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    4.2s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   16.7s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    4.2s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   14.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.1470            2.29m\n",
            "         2           1.0427            2.18m\n",
            "         3           0.9663            2.33m\n",
            "         4           0.9151            2.27m\n",
            "         5           0.8701            2.26m\n",
            "         6           0.8359            2.23m\n",
            "         7           0.8004            2.23m\n",
            "         8           0.7780            2.21m\n",
            "         9           0.7477            2.23m\n",
            "        10           0.7252            2.21m\n",
            "        20           0.6153            2.04m\n",
            "        30           0.5479            1.98m\n",
            "        40           0.5001            1.94m\n",
            "        50           0.4566            1.92m\n",
            "        60           0.4238            1.89m\n",
            "        70           0.3959            1.89m\n",
            "        80           0.3772            1.86m\n",
            "        90           0.3583            1.85m\n",
            "       100           0.3398            1.83m\n",
            "       200           0.2394            1.72m\n",
            "       300           0.1906            1.66m\n",
            "       400           0.1606            1.61m\n",
            "       500           0.1406            1.57m\n",
            "       600           0.1282            1.53m\n",
            "       700           0.1191            1.49m\n",
            "       800           0.1128            1.46m\n",
            "       900           0.1083            1.42m\n",
            "      1000           0.1051            1.39m\n",
            "      2000           0.0952            1.06m\n",
            "      3000           0.0936           42.78s\n",
            "      4000           0.0930           21.52s\n",
            "      5000           0.0928            0.00s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9798747763864043\n",
            "[[1578   38]\n",
            " [  52 2804]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      1616\n",
            "           1       0.99      0.98      0.98      2856\n",
            "\n",
            "    accuracy                           0.98      4472\n",
            "   macro avg       0.98      0.98      0.98      4472\n",
            "weighted avg       0.98      0.98      0.98      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU5wBb7R8SxQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36250e55-df93-43c5-df7f-07bf8643a57c"
      },
      "source": [
        "countVecclf.fit(X_T, y)\n",
        "#saving model then reading it again\n",
        "pickle.dump(countVecclf, open('finalBestModel.sav', 'wb'))\n",
        "countVecclf = pickle.load(open('finalBestModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 122 tasks      | elapsed:    3.7s\n",
            "[Parallel(n_jobs=-1)]: Done 722 tasks      | elapsed:   17.7s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   24.0s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed:    3.3s\n",
            "[Parallel(n_jobs=-1)]: Done 764 tasks      | elapsed:   15.7s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   20.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.1473            3.17m\n",
            "         2           1.0429            3.09m\n",
            "         3           0.9674            3.04m\n",
            "         4           0.9163            2.96m\n",
            "         5           0.8702            2.95m\n",
            "         6           0.8363            2.95m\n",
            "         7           0.8019            2.92m\n",
            "         8           0.7658            2.93m\n",
            "         9           0.7483            2.90m\n",
            "        10           0.7290            2.88m\n",
            "        20           0.6243            2.75m\n",
            "        30           0.5525            2.69m\n",
            "        40           0.5055            2.66m\n",
            "        50           0.4663            2.60m\n",
            "        60           0.4348            2.55m\n",
            "        70           0.4070            2.55m\n",
            "        80           0.3819            2.52m\n",
            "        90           0.3660            2.49m\n",
            "       100           0.3476            2.48m\n",
            "       200           0.2467            2.35m\n",
            "       300           0.1941            2.26m\n",
            "       400           0.1642            2.20m\n",
            "       500           0.1449            2.14m\n",
            "       600           0.1317            2.09m\n",
            "       700           0.1226            2.03m\n",
            "       800           0.1162            1.99m\n",
            "       900           0.1112            1.94m\n",
            "      1000           0.1078            1.90m\n",
            "      2000           0.0972            1.44m\n",
            "      3000           0.0955           58.23s\n",
            "      4000           0.0948           29.30s\n",
            "      5000           0.0945            0.00s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvT9Jma18Udk"
      },
      "source": [
        "# With TF-IDF vectorizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On6Sv1u_8Udl",
        "outputId": "19ce2dc6-4656-4af8-a538-4129ffe4b0e3"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(tokenizer = preprocessing)#,stop_words=stop_words\n",
        "X_trainT = vectorizer.fit_transform(X_train)\n",
        "features = vectorizer.get_feature_names()\n",
        "print(\"No of features after vectorizing X_train:\", len(features))\n",
        "X_testT  = vectorizer.transform(X_test)\n",
        "print(\"shape of X_trainT:\", X_trainT.shape)\n",
        "X_T = vectorizer.fit_transform(X)\n",
        "# print(X_testT)\n",
        "# vectorizer.vocabulary_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of features after vectorizing X_train: 10685\n",
            "shape of X_trainT: (9077, 10685)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_i53Qme8Udl",
        "outputId": "adf288cd-2f28-43ed-c813-500a740d13b9"
      },
      "source": [
        "#applying different models\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "MNBclf = MultinomialNB(class_prior = [0.5, 0.5])\n",
        "y_train = y_train.astype('i')\n",
        "print(y_train.dtype)\n",
        "MNBclf.fit(X_trainT, y_train)\n",
        "\n",
        "y_pred = MNBclf.predict(X_testT)\n",
        "print(\"shape of y pred\",y_pred.shape)\n",
        "print(\"shape of y test\",y_test.shape)\n",
        "print(y_pred[:100])\n",
        "print(y_test[:100])\n",
        "y_test = y_test.astype('i')\n",
        "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "\n",
        "print(classification_report(y_test,y_pred))\n",
        "# X_trainT\n",
        "#saving model then reading it again\n",
        "pickle.dump(MNBclf, open('MNBclfModel.sav', 'wb'))\n",
        "MNBclf = pickle.load(open('MNBclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "int32\n",
            "shape of y pred (4472,)\n",
            "shape of y test (4472,)\n",
            "[1 0 1 1 0 1 0 0 1 1 0 0 0 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 0 1 0\n",
            " 1 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0\n",
            " 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 0]\n",
            "[1 0 1 1 0 1 0 0 1 1 0 1 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 0 1 1 0\n",
            " 1 1 1 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 0 1 0\n",
            " 0 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 0 1 0 0 0 0 0 1 1]\n",
            "Accuracy:  0.9557245080500895\n",
            "[[1555   61]\n",
            " [ 137 2719]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.96      0.94      1616\n",
            "           1       0.98      0.95      0.96      2856\n",
            "\n",
            "    accuracy                           0.96      4472\n",
            "   macro avg       0.95      0.96      0.95      4472\n",
            "weighted avg       0.96      0.96      0.96      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOui1Ii98Udm",
        "outputId": "b5029e08-a0ad-4350-bbdc-5c1ea1dd7534"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "LOGclf = LogisticRegression(random_state=0, n_jobs = -1, max_iter = 1000, verbose= 1)\n",
        "LOGclf.fit(X_trainT, y_train)\n",
        "\n",
        "y_pred = LOGclf.predict(X_testT)\n",
        "\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#saving model then reading it again\n",
        "pickle.dump(LOGclf, open('tfIDFLOGclfModel.sav', 'wb'))\n",
        "LOGclf = pickle.load(open('tfIDFLOGclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.7s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9566189624329159\n",
            "[[1488  128]\n",
            " [  66 2790]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.92      0.94      1616\n",
            "           1       0.96      0.98      0.97      2856\n",
            "\n",
            "    accuracy                           0.96      4472\n",
            "   macro avg       0.96      0.95      0.95      4472\n",
            "weighted avg       0.96      0.96      0.96      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7Cu0-5w8Udm",
        "outputId": "d1c2251c-fcd5-4793-9800-9bdcddfaedf3"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier #take more than 3 min (1m2s 75), (27m, 90.8%)\n",
        "KNNclf = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski',n_jobs = -1)\n",
        "KNNclf.fit(X_trainT, y_train)\n",
        "# Predicting the Test set results\n",
        "y_pred = KNNclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#saving model then reading it again\n",
        "pickle.dump(KNNclf, open('tfIDFKNNclfModel.sav', 'wb'))\n",
        "KNNclf = pickle.load(open('tfIDFKNNclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9499105545617174\n",
            "[[1553   63]\n",
            " [ 161 2695]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.96      0.93      1616\n",
            "           1       0.98      0.94      0.96      2856\n",
            "\n",
            "    accuracy                           0.95      4472\n",
            "   macro avg       0.94      0.95      0.95      4472\n",
            "weighted avg       0.95      0.95      0.95      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAZL8pPi8Udn",
        "outputId": "b6b4e6f8-0655-44aa-97a4-3f8044d79ebd"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "GNBclf = GaussianNB()\n",
        "GNBclf.fit(X_trainT.toarray(), y_train)\n",
        "y_pred = GNBclf.predict(X_testT.toarray())\n",
        "\n",
        "print(\"Accuracy: \",accuracy_score(y_test, y_pred))\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#saving model then reading it again\n",
        "pickle.dump(GNBclf, open('tfIDFGNBclfModel.sav', 'wb'))\n",
        "GNBclf = pickle.load(open('tfIDFGNBclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy:  0.8696332737030411\n",
            "[[1616    0]\n",
            " [ 583 2273]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      1.00      0.85      1616\n",
            "           1       1.00      0.80      0.89      2856\n",
            "\n",
            "    accuracy                           0.87      4472\n",
            "   macro avg       0.87      0.90      0.87      4472\n",
            "weighted avg       0.90      0.87      0.87      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgKbRJ1W8Udp",
        "outputId": "b60369b1-f328-46c9-a6b1-a097f075ed7c"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "SVMclf = SVC(probability=False,random_state=1, kernel='rbf')\n",
        "SVMclf.fit(X_trainT, y_train)\n",
        "# Predicting the Test set results\n",
        "y_pred = SVMclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#saving model then reading it again\n",
        "pickle.dump(SVMclf, open('tfIDFSVMclfModel.sav', 'wb'))\n",
        "SVMclf = pickle.load(open('tfIDFSVMclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9803220035778175\n",
            "[[1578   38]\n",
            " [  50 2806]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      1616\n",
            "           1       0.99      0.98      0.98      2856\n",
            "\n",
            "    accuracy                           0.98      4472\n",
            "   macro avg       0.98      0.98      0.98      4472\n",
            "weighted avg       0.98      0.98      0.98      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "inBwLo3H8Udq",
        "outputId": "142d6cfc-64ce-42dc-e0d6-c93ab955b119"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier  #5s 78%\n",
        "RFclf = RandomForestClassifier(max_depth = 39, bootstrap = True, n_estimators = 1000, criterion = 'gini', random_state = 1,n_jobs = -1, verbose = 1)\n",
        "RFclf.fit(X_trainT, y_train)\n",
        "\n",
        "y_pred = RFclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "#12>89.44\n",
        "#20>95.7\n",
        "#100, 40, 95.8\n",
        "#100, 35, 95.88\n",
        "#100, pca30, 92\n",
        "#100, w/oPcA 400, 96.03\n",
        "#saving model then reading it again\n",
        "pickle.dump(RFclf, open('tfIDFRFclfModel.sav', 'wb'))\n",
        "RFclf = pickle.load(open('tfIDFRFclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    0.8s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:    3.1s\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:    6.9s\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:   12.3s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   15.5s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9123434704830053\n",
            "[[1252  364]\n",
            " [  28 2828]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.77      0.86      1616\n",
            "           1       0.89      0.99      0.94      2856\n",
            "\n",
            "    accuracy                           0.91      4472\n",
            "   macro avg       0.93      0.88      0.90      4472\n",
            "weighted avg       0.92      0.91      0.91      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGRFGPNG8Udq",
        "outputId": "ed748c4b-e2e0-4b21-f8cf-caae87fa13a1"
      },
      "source": [
        "from sklearn.ensemble import ExtraTreesClassifier  #5s 78%\n",
        "ETclf = ExtraTreesClassifier(max_depth = 39, bootstrap = True, n_estimators = 1000, criterion = 'gini', random_state = 1,n_jobs = -1, verbose = 1)\n",
        "ETclf.fit(X_trainT, y_train)\n",
        "\n",
        "y_pred = ETclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n",
        "#12>89.44\n",
        "#20>95.7\n",
        "#100, 40, 95.8\n",
        "#100, 35, 95.88\n",
        "#100, pca30, 92\n",
        "#100, w/oPcA 400, 96.03\n",
        "#saving model then reading it again\n",
        "pickle.dump(ETclf, open('tfIDFETclfModel.sav', 'wb'))\n",
        "ETclf = pickle.load(open('tfIDFETclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:    0.7s\n",
            "[Parallel(n_jobs=-1)]: Done 196 tasks      | elapsed:    2.7s\n",
            "[Parallel(n_jobs=-1)]: Done 446 tasks      | elapsed:    6.1s\n",
            "[Parallel(n_jobs=-1)]: Done 796 tasks      | elapsed:   10.6s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   13.3s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.8926654740608229\n",
            "[[1161  455]\n",
            " [  25 2831]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.72      0.83      1616\n",
            "           1       0.86      0.99      0.92      2856\n",
            "\n",
            "    accuracy                           0.89      4472\n",
            "   macro avg       0.92      0.85      0.88      4472\n",
            "weighted avg       0.90      0.89      0.89      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLSxX9TB8Udq",
        "outputId": "64733302-00aa-43c7-8637-dede52b23c9b"
      },
      "source": [
        "from sklearn.neural_network import MLPClassifier #(1m 48s 70)\n",
        "MLPclf = MLPClassifier(batch_size = 512, early_stopping=True, hidden_layer_sizes=(256,128,64,32,16), random_state=37 ,max_iter=450, learning_rate_init=0.01, tol=0.0000001,n_iter_no_change = 20) #, verbose = True\n",
        "MLPclf.fit(X_trainT, y_train)\n",
        "# Predicting the Test set results\n",
        "# print(X_train.shape)\n",
        "y_pred = MLPclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "pickle.dump(MLPclf, open('tfIDFbestMLPModel.sav', 'wb'))\n",
        "MLPclf = pickle.load(open('tfIDFbestMLPModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9771914132379249\n",
            "[[1585   31]\n",
            " [  71 2785]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.98      0.97      1616\n",
            "           1       0.99      0.98      0.98      2856\n",
            "\n",
            "    accuracy                           0.98      4472\n",
            "   macro avg       0.97      0.98      0.98      4472\n",
            "weighted avg       0.98      0.98      0.98      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzIdFDZq8Udr",
        "outputId": "2e9457b1-faf3-49c8-e426-028bde1683a7"
      },
      "source": [
        "from xgboost import XGBClassifier #(1m 14s 78)\n",
        "XGBclf = XGBClassifier(max_depth = 15, n_estimators = 2000, n_jobs = -1,random_state=37, verbosity=1)\n",
        "XGBclf.fit(X_trainT, y_train)\n",
        "y_pred = XGBclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(classification_report(y_test,y_pred))\n",
        "\n",
        "#saving model then reading it again\n",
        "pickle.dump(XGBclf, open('tfIDFXGBclfModel.sav', 'wb'))\n",
        "XGBclf = pickle.load(open('tfIDFXGBclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9774150268336315\n",
            "[[1590   26]\n",
            " [  75 2781]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97      1616\n",
            "           1       0.99      0.97      0.98      2856\n",
            "\n",
            "    accuracy                           0.98      4472\n",
            "   macro avg       0.97      0.98      0.98      4472\n",
            "weighted avg       0.98      0.98      0.98      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVdwDdwz8Udr",
        "outputId": "0e48fe3a-d996-4083-d343-ed5c5b737a30"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier  #1m 54s 67\n",
        "ADBclf = AdaBoostClassifier(n_estimators=10000, random_state=37, learning_rate = 0.1, algorithm='SAMME')\n",
        "ADBclf.fit(X_trainT, y_train)\n",
        "y_pred = ADBclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))  \n",
        "print(classification_report(y_test,y_pred))\n",
        "#0.8,1000 > 88.95\n",
        "#0.8, 100 > 82\n",
        "#1, 100 > 84.3\n",
        "#saving model then reading it again\n",
        "pickle.dump(ADBclf, open('tfIDFADBclfModel.sav', 'wb'))\n",
        "ADBclf = pickle.load(open('tfIDFADBclfModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.8819320214669052\n",
            "[[1151  465]\n",
            " [  63 2793]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.71      0.81      1616\n",
            "           1       0.86      0.98      0.91      2856\n",
            "\n",
            "    accuracy                           0.88      4472\n",
            "   macro avg       0.90      0.85      0.86      4472\n",
            "weighted avg       0.89      0.88      0.88      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOYUmP2J8Uds",
        "outputId": "c749120b-0eca-44c9-9d97-7a555746ab0e"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier #6 min #13s 69 #2m6s 73\n",
        "GBclf = GradientBoostingClassifier(n_estimators=5000, learning_rate=0.2,max_depth=5, random_state=37, verbose = 1)\n",
        "GBclf.fit(X_trainT, y_train)\n",
        "y_pred = GBclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred))  \n",
        "print(classification_report(y_test,y_pred))\n",
        "#saving model then reading it again\n",
        "pickle.dump(GBclf, open('tfIDFGBclfModel.sav', 'wb'))\n",
        "GBclf = pickle.load(open('tfIDFGBclfModel.sav', 'rb'))\n",
        "#89"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.1459            3.38m\n",
            "         2           1.0385            3.35m\n",
            "         3           0.9688            3.30m\n",
            "         4           0.9110            3.29m\n",
            "         5           0.8600            3.32m\n",
            "         6           0.8294            3.35m\n",
            "         7           0.8009            3.35m\n",
            "         8           0.7709            3.38m\n",
            "         9           0.7457            3.40m\n",
            "        10           0.7268            3.39m\n",
            "        20           0.6003            3.36m\n",
            "        30           0.5265            3.34m\n",
            "        40           0.4796            3.32m\n",
            "        50           0.4416            3.29m\n",
            "        60           0.4083            3.25m\n",
            "        70           0.3810            3.23m\n",
            "        80           0.3594            3.20m\n",
            "        90           0.3385            3.19m\n",
            "       100           0.3215            3.17m\n",
            "       200           0.2232            3.02m\n",
            "       300           0.1758            2.95m\n",
            "       400           0.1471            2.88m\n",
            "       500           0.1306            2.81m\n",
            "       600           0.1194            2.75m\n",
            "       700           0.1121            2.68m\n",
            "       800           0.1073            2.61m\n",
            "       900           0.1037            2.55m\n",
            "      1000           0.1014            2.49m\n",
            "      2000           0.0943            1.88m\n",
            "      3000           0.0932            1.26m\n",
            "      4000           0.0928           37.85s\n",
            "      5000           0.0926            0.00s\n",
            "Testing accuracy: 0.9767441860465116\n",
            "[[1590   26]\n",
            " [  78 2778]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.98      0.97      1616\n",
            "           1       0.99      0.97      0.98      2856\n",
            "\n",
            "    accuracy                           0.98      4472\n",
            "   macro avg       0.97      0.98      0.97      4472\n",
            "weighted avg       0.98      0.98      0.98      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcmYTclI8Uds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04a9727d-fd88-4bc1-b3ba-4437568ec360"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier \n",
        "RFclf = RandomForestClassifier(max_depth = 39, bootstrap = True, n_estimators = 1000, criterion = 'gini', random_state = 1,n_jobs = -1, verbose = 1)\n",
        "\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "# ETclf = ExtraTreesClassifier(max_depth = 39, bootstrap = True, n_estimators = 500, criterion = 'gini', n_jobs = -1,max_samples=0.8,max_features=6,random_state=37)\n",
        "ETclf = ExtraTreesClassifier(max_depth = 39, bootstrap = True, n_estimators = 1000, criterion = 'gini', random_state = 1,n_jobs = -1, verbose = 1)\n",
        "\n",
        "\n",
        "# from sklearn.naive_bayes import MultinomialNB\n",
        "# MNBclf = MultinomialNB()\n",
        "\n",
        "# from sklearn.neighbors import KNeighborsClassifier #take more than 3 min\n",
        "# KNNclf = KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski',n_jobs = -1)\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier #\n",
        "MLPclf = MLPClassifier(batch_size = 512, early_stopping=True, hidden_layer_sizes=(256,128,64,32,16), random_state=37 ,max_iter=450, learning_rate_init=0.01, tol=0.0000001,n_iter_no_change = 20) # , verbose = True\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression #\n",
        "LOGclf = LogisticRegression(random_state=0, n_jobs = -1, max_iter = 200, verbose= 1)\n",
        "\n",
        "from sklearn.svm import SVC #\n",
        "SVMclf = SVC(probability=False,random_state=1, kernel='rbf')\n",
        "\n",
        "from xgboost import XGBClassifier #\n",
        "XGBclf = XGBClassifier(max_depth = 15, n_estimators = 10000, n_jobs = -1,random_state=37, verbosity=1)\n",
        "\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ADBclf = AdaBoostClassifier(n_estimators=30000, random_state=37, learning_rate = 0.1, algorithm='SAMME')\n",
        "\n",
        "from sklearn.ensemble import GradientBoostingClassifier #6 min\n",
        "GBclf = GradientBoostingClassifier(n_estimators=5000, learning_rate=0.2,max_depth=5, random_state=37, verbose = 1)\n",
        "\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "tfIDFclf = VotingClassifier(estimators=[('RFclf', RFclf),('ETclf', ETclf),('MLPclf', MLPclf),('LOGclf', LOGclf),('SVMclf', SVMclf), ('XGBclf', XGBclf),  ('ADBclf', ADBclf),('GBclf', GBclf)], voting='hard', weights=[1,1,2,2,2,2,1,2], flatten_transform=True)\n",
        "tfIDFclf.fit(X_trainT, y_train)\n",
        "y_pred_tfIDF = tfIDFclf.predict(X_testT)\n",
        "#for accuracy using sklearn accuracy_score\n",
        "AccuracyScore = accuracy_score(y_test, y_pred_tfIDF)\n",
        "print(\"Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred_tfIDF))  \n",
        "print(classification_report(y_test,y_pred_tfIDF))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 216 tasks      | elapsed:    4.2s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   16.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 300 tasks      | elapsed:    4.1s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   13.4s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.1459            3.36m\n",
            "         2           1.0385            3.32m\n",
            "         3           0.9688            3.25m\n",
            "         4           0.9110            3.24m\n",
            "         5           0.8600            3.31m\n",
            "         6           0.8294            3.34m\n",
            "         7           0.8009            3.34m\n",
            "         8           0.7709            3.35m\n",
            "         9           0.7457            3.36m\n",
            "        10           0.7268            3.34m\n",
            "        20           0.6003            3.29m\n",
            "        30           0.5265            3.28m\n",
            "        40           0.4796            3.25m\n",
            "        50           0.4416            3.22m\n",
            "        60           0.4083            3.19m\n",
            "        70           0.3810            3.16m\n",
            "        80           0.3594            3.14m\n",
            "        90           0.3385            3.12m\n",
            "       100           0.3215            3.11m\n",
            "       200           0.2232            2.98m\n",
            "       300           0.1758            2.89m\n",
            "       400           0.1471            2.84m\n",
            "       500           0.1306            2.77m\n",
            "       600           0.1194            2.70m\n",
            "       700           0.1121            2.64m\n",
            "       800           0.1073            2.58m\n",
            "       900           0.1037            2.52m\n",
            "      1000           0.1014            2.46m\n",
            "      2000           0.0943            1.85m\n",
            "      3000           0.0932            1.24m\n",
            "      4000           0.0928           37.30s\n",
            "      5000           0.0926            0.00s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n",
            "[Parallel(n_jobs=2)]: Using backend ThreadingBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=2)]: Done  46 tasks      | elapsed:    0.0s\n",
            "[Parallel(n_jobs=2)]: Done 196 tasks      | elapsed:    0.1s\n",
            "[Parallel(n_jobs=2)]: Done 446 tasks      | elapsed:    0.3s\n",
            "[Parallel(n_jobs=2)]: Done 796 tasks      | elapsed:    0.5s\n",
            "[Parallel(n_jobs=2)]: Done 1000 out of 1000 | elapsed:    0.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing accuracy: 0.9814400715563506\n",
            "[[1583   33]\n",
            " [  50 2806]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      1616\n",
            "           1       0.99      0.98      0.99      2856\n",
            "\n",
            "    accuracy                           0.98      4472\n",
            "   macro avg       0.98      0.98      0.98      4472\n",
            "weighted avg       0.98      0.98      0.98      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2RwCRdLY5tmL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26606079-54b7-4b09-80e3-bbab757db338"
      },
      "source": [
        "tfIDFclf.fit(X_T, y)\n",
        "#saving model then reading it again\n",
        "pickle.dump(tfIDFclf, open('tfIDFfinalBestModel.sav', 'wb'))\n",
        "tfIDFclf = pickle.load(open('tfIDFfinalBestModel.sav', 'rb'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 128 tasks      | elapsed:    3.8s\n",
            "[Parallel(n_jobs=-1)]: Done 728 tasks      | elapsed:   17.6s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   23.8s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done 164 tasks      | elapsed:    3.2s\n",
            "[Parallel(n_jobs=-1)]: Done 764 tasks      | elapsed:   15.0s\n",
            "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   19.6s finished\n",
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "      Iter       Train Loss   Remaining Time \n",
            "         1           1.1464            4.48m\n",
            "         2           1.0499            4.45m\n",
            "         3           0.9802            4.46m\n",
            "         4           0.9161            4.48m\n",
            "         5           0.8639            4.53m\n",
            "         6           0.8295            4.53m\n",
            "         7           0.7949            4.59m\n",
            "         8           0.7705            4.60m\n",
            "         9           0.7461            4.63m\n",
            "        10           0.7222            4.60m\n",
            "        20           0.6057            4.57m\n",
            "        30           0.5218            4.52m\n",
            "        40           0.4729            4.47m\n",
            "        50           0.4338            4.42m\n",
            "        60           0.4066            4.39m\n",
            "        70           0.3771            4.37m\n",
            "        80           0.3584            4.33m\n",
            "        90           0.3395            4.31m\n",
            "       100           0.3229            4.30m\n",
            "       200           0.2270            4.12m\n",
            "       300           0.1785            4.00m\n",
            "       400           0.1505            3.91m\n",
            "       500           0.1331            3.82m\n",
            "       600           0.1224            3.73m\n",
            "       700           0.1152            3.64m\n",
            "       800           0.1101            3.56m\n",
            "       900           0.1065            3.48m\n",
            "      1000           0.1040            3.40m\n",
            "      2000           0.0962            2.56m\n",
            "      3000           0.0950            1.71m\n",
            "      4000           0.0945           51.45s\n",
            "      5000           0.0943            0.00s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3AoRbXmVt1h"
      },
      "source": [
        "pickle.dump(y_pred_tfIDF, open('y_pred_tfIDF.sav', 'wb'))\n",
        "pickle.dump(y_pred_otherFeature, open('y_pred_otherFeature.sav', 'wb'))\n",
        "pickle.dump(y_pred_countVec, open('y_pred_countVec.sav', 'wb'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7O_2A8MYiJMP"
      },
      "source": [
        "# Cummulative Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFt1MlpVV3RV"
      },
      "source": [
        "y_pred_tfIDF = pickle.load(open('y_pred_tfIDF.sav', 'rb'))\n",
        "y_pred_otherFeature = pickle.load(open('y_pred_otherFeature.sav', 'rb'))\n",
        "y_pred_countVec = pickle.load(open('y_pred_countVec.sav', 'rb'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hj61eKqoiR0j",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46c68012-725e-4838-c843-3ec1bddfe362"
      },
      "source": [
        "from scipy import stats\n",
        "y_pred_final = np.array([y_pred_otherFeature, y_pred_tfIDF, y_pred_countVec])\n",
        "y_pred_final = stats.mode(y_pred_final)\n",
        "y_pred_final = y_pred_final[0][0]\n",
        "# print(y_pred_final)\n",
        "AccuracyScore = accuracy_score(y_test, y_pred_final)\n",
        "print(\"final Testing accuracy:\", AccuracyScore)\n",
        "print(confusion_matrix(y_test, y_pred_final))  \n",
        "print(classification_report(y_test,y_pred_final))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "final Testing accuracy: 0.9816636851520573\n",
            "[[1583   33]\n",
            " [  49 2807]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.98      0.97      1616\n",
            "           1       0.99      0.98      0.99      2856\n",
            "\n",
            "    accuracy                           0.98      4472\n",
            "   macro avg       0.98      0.98      0.98      4472\n",
            "weighted avg       0.98      0.98      0.98      4472\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJDCKamX9p6i"
      },
      "source": [
        "# Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKcTILSl9pNT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8d80feb-5f9e-4f51-a466-baef15121aeb"
      },
      "source": [
        "from textblob import TextBlob\n",
        "sentiment = np.zeros(len(X))\n",
        "for i in range(len(X)):\n",
        "  analysis = TextBlob(X[i])\n",
        "  if analysis.sentiment.polarity > 0:\n",
        "      sentiment[i] = 1\n",
        "  elif analysis.sentiment.polarity < 0:\n",
        "      sentiment[i] = -1\n",
        "hijPos = 0; hijNeg = 0; hijNeu = 0\n",
        "unHijPos = 0; unHijNeg = 0; unHiNeu = 0\n",
        "hijacked = 0; unhijacked = 0\n",
        "for i in range(len(X)):\n",
        "  if(y[i] == 0):\n",
        "    hijacked += 1\n",
        "    if(sentiment[i] == -1):\n",
        "      hijNeg += 1\n",
        "    elif(sentiment[i] == 1):\n",
        "      hijPos += 1\n",
        "    else:\n",
        "      hijNeu += 1\n",
        "  elif(y[i] == 1):\n",
        "    unhijacked += 1\n",
        "    if(sentiment[i] == -1):\n",
        "      unHijNeg += 1\n",
        "    elif(sentiment[i] == 1):\n",
        "      unHijPos += 1  \n",
        "    else:\n",
        "      unHiNeu += 1  \n",
        "\n",
        "n = len(X)\n",
        "\n",
        "print(\"Positive sentiment in Hijacked tweets\", hijPos*100/hijacked, '%')\n",
        "print(\"Negative sentiment in Hijacked tweets\", hijNeg*100/hijacked, '%')\n",
        "print(\"Neutral sentiment in Hijacked tweets\", hijNeu*100/hijacked, '%')\n",
        "\n",
        "print(\"Positive sentiment in UnHijacked tweets\", unHijPos*100/unhijacked, '%')\n",
        "print(\"Negative sentiment in UnHijacked tweets\", unHijNeg*100/unhijacked, '%')\n",
        "print(\"Neutral sentiment in Hijacked tweets\", unHiNeu*100/unhijacked, '%')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Positive sentiment in Hijacked tweets 49.509803921568626 %\n",
            "Negative sentiment in Hijacked tweets 5.147058823529412 %\n",
            "Neutral sentiment in Hijacked tweets 45.34313725490196 %\n",
            "Positive sentiment in UnHijacked tweets 33.47971801687276 %\n",
            "Negative sentiment in UnHijacked tweets 17.311914942794406 %\n",
            "Neutral sentiment in Hijacked tweets 49.20836704033283 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvScB4hx9_mc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}